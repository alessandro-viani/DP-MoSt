{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["%matplotlib inline\n","import numpy as np\n","import torch\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import pickle\n","import platform\n","import sys\n","import warnings\n","import pySuStaIn\n","from sklearn.metrics import roc_curve, auc\n","import matplotlib.image as mpimg\n","from pathlib import Path\n","\n","import statsmodels.formula.api as smf\n","import os\n","from DPMoSt import DPMoSt\n","from utility import data_creation, plot_data, plot_solution, error_eval\n","\n","folder='/media/aviani/External HD/postdoc/gppm' if platform.system()=='Linux' else '/Volumes/External HD/postdoc/gppm'\n","sys.path.insert(1, f'{folder}')\n","import GP_progression_model # type: ignore"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["warnings.filterwarnings(\"ignore\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["random_state=42\n","torch.manual_seed(random_state)\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","device='cpu'\n","print(f'Device used: {device}')"]},{"cell_type":"markdown","metadata":{},"source":["# Data Creation"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["n_features=2\n","n_subjects=20\n","n_time_for_subject=1\n","device='cpu'\n","dpi=500\n","\n","create_data=False\n","run_dpmost=False\n","run_gppm=False\n","run_sustain=False\n","\n","name=f'n_features_{n_features}_n_subjects_{n_subjects}_n_time_for_subject_{n_time_for_subject}'\n","output_folder=f'examples/example_{name}'\n","Path(f'{output_folder}').mkdir(parents=True, exist_ok=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if not os.path.isfile(f'{output_folder}/dpmost_data.pkl'):\n","    dict_data=data_creation(n_subjects=n_subjects, \n","                            n_time_points=n_time_for_subject, \n","                            n_features=n_features, \n","                            name_path=output_folder,\n","                            noise_std=0.5, \n","                            max_dist=1, \n","                            time_shifted=True, \n","                            device='cpu')\n","else:\n","    with open(f'{output_folder}/dpmost_data.pkl', 'rb') as f:\n","        dict_data = pickle.load(f) \n","data=dict_data['data']\n","plot_data(data, dict_data=dict_data, dpi=dpi, name_path=f'{output_folder}/data', save=True)"]},{"cell_type":"markdown","metadata":{},"source":["# DP-MoSt"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if not os.path.isfile(f'{output_folder}/dpmost_sol.pkl'):\n","    dpmost=DPMoSt(data=data, \n","                  device=device, \n","                  benchmarks=False,\n","                  stopping_criteria=True,\n","                  name_path=output_folder,\n","                  verbose=True)\n","\n","    dpmost.optimise(n_outer_iterations=20, n_inner_iterations=20, lr=1e-1)\n","    dpmost.save()\n","else:\n","    with open(f'{output_folder}/dpmost_sol.pkl', 'rb') as f:\n","        dpmost = pickle.load(f) "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dpmost=DPMoSt(data=data, \n","            device=device, \n","            n_prints=5, \n","            benchmarks=True, \n","            stopping_criteria=False,\n","            name_path=output_folder,\n","            lambda_reg_theta=0.001,\n","            verbose=True)\n","\n","dpmost.optimise(n_outer_iterations=20, n_inner_iterations=20, lr=1e-1)"]},{"cell_type":"markdown","metadata":{},"source":["# Error evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["error_ospa, error_noise = error_eval(dpmost, dict_data)\n","print(f'Error OSPA: {error_ospa}\\nError noise: {error_noise}')"]},{"cell_type":"markdown","metadata":{},"source":["# GPPM"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["input_data=data.copy()\n","reparameterization_model='time_shift'\n","monotonicity = [1 for k in range(data.iloc[:,2:].shape[1])]\n","input_data.rename(columns={\"subj_id\": \"RID\"}, inplace=True)\n","Xdata, Ydata, RID, list_biomarkers, group = GP_progression_model.convert_from_df(input_data, input_data.iloc[:,2:].columns, time_var='time')\n","\n","N_outer_iterations=6\n","N_iterations=200\n","n_minibatch=5\n","# create a GPPM object\n","model = GP_progression_model.GP_Progression_Model(x=Xdata, \n","                                                  y=Ydata, \n","                                                  names_biomarkers=input_data.iloc[:,2:].columns,\n","                                                  monotonicity=monotonicity, \n","                                                  trade_off=50, \n","                                                  reparameterization_model=reparameterization_model, \n","                                                  sigma_0=10, \n","                                                  device=device)\n","\n","if not os.path.isfile(f'{output_folder}/gppm_sol.pkl'):\n","     model.model = model.model.to(device)\n","     # Optimise the model\n","     model.Optimize(N_outer_iterations=N_outer_iterations, N_iterations=N_iterations, \n","                n_minibatch=n_minibatch, verbose=True, plot=False, benchmark=False)\n","    \n","     model.Save(f'{output_folder}/', name=f'gppm_sol')\n","else:\n","     model.Load(f'{output_folder}/', name=f'gppm_sol')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y = []\n","t = []\n","model.tr.list_id = np.arange(len(model.x[0])).tolist()\n","\n","x_min, x_max = np.inf, -np.inf\n","y_min, y_max = np.inf, -np.inf\n","\n","for bio_pos, biomarker in enumerate(model.names_biomarkers):\n","    bio_id = np.where([model.names_biomarkers[i] == biomarker for i in range(model.N_biomarkers)])[0][0]\n","    x_data = model.model.time_reparameterization(model.x_torch)[bio_id].detach().data.cpu().numpy()\n","    y_data = model.y_torch[bio_id].detach().data.cpu().numpy()\n","    y.append(y_data)\n","\n","    x_min = min(x_min, np.float64(np.min(x_data)))\n","    x_max = max(x_max, np.float64(np.max(x_data)))\n","    y_min = min(y_min, np.float64(np.min(y_data)))\n","    y_max = max(y_max, np.float64(np.max(y_data)))\n","\n","    x_range = torch.autograd.Variable(torch.arange(x_min, x_max, np.float64((x_max - x_min) / 50)))\n","    x_range = x_range.reshape(x_range.size()[0], 1)\n","\n","    new_x = model.Transform_subjects()\n","    t.append((x_data * model.x_mean_std[bio_id][1] + model.x_mean_std[bio_id][0]).flatten())\n","\n","t=torch.tensor(t[0], dtype=torch.float32, device=device)\n","y=torch.tensor(np.array(y), dtype=torch.float32, device=device).T\n","\n","for fdx in range(input_data.iloc[:,2:].shape[1]):\n","    y_min, y_max = y[:,fdx].min(), y[:,fdx].max()\n","    new_max=data.iloc[:,2+fdx].max()\n","    new_min=data.iloc[:,2+fdx].min()\n","    y_new = (y[:,fdx] - y_min)/(y_max - y_min)*(new_max - new_min) + new_min\n","    input_data.iloc[:,2+fdx]=y_new.cpu().numpy()\n","\n","t_min, t_max = t.min(), t.max()\n","new_max=20\n","new_min=0\n","t_new = (t - t_min)/(t_max - t_min)*(new_max - new_min) + new_min\n","\n","input_data['time']=t_new.cpu().numpy()\n","input_data.rename(columns={\"RID\": \"subj_id\"}, inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plot_data(input_data, dict_data=dict_data, alpha=0, name_path=f'{output_folder}/gppm_sol', dpi=dpi)"]},{"cell_type":"markdown","metadata":{},"source":["# SuStaIn"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["zdata = data.copy()\n","# for each biomarker\n","for biomarker in zdata.columns[2:]:\n","    mod = smf.ols('%s ~ time'%biomarker, data=zdata).fit()    \n","    predicted = mod.predict(zdata[['time',biomarker]])     \n","    w_score = (zdata.loc[:,biomarker] - predicted) / mod.resid.std()\n","    zdata.loc[:,biomarker] = w_score"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["Z_vals = np.array([[0.5,1,1.5]]*dict_data['n_features'])     # Z-scores for each biomarker\n","Z_max = np.array([5]*dict_data['n_features'])           # maximum z-score\n","N_S_max=3\n","N_iterations_MCMC=int(1e4)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Initiate the SuStaIn object\n","sustain_input = pySuStaIn.ZscoreSustain(\n","                            zdata[zdata.columns[2:]].values,\n","                            Z_vals=Z_vals,\n","                            Z_max=Z_max,\n","                            biomarker_labels=zdata.columns[2:],\n","                            N_startpoints=15,\n","                            N_S_max=N_S_max, \n","                            N_iterations_MCMC=N_iterations_MCMC, \n","                            output_folder=output_folder, \n","                            dataset_name=f'sustain_sol', \n","                            use_parallel_startpoints=True)\n","\n","_=sustain_input.run_sustain_algorithm()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# for each subtype model\n","all_like_mean=np.zeros(N_S_max)\n","plt.figure(figsize=(10,3))\n","for s in range(N_S_max):\n","    # load pickle file (SuStaIn output) and get the sample log likelihood values\n","    pickle_filename_s = output_folder + f'/pickle_files/sustain_sol_subtype' + str(s) + '.pickle'\n","    pk = pd.read_pickle(pickle_filename_s)\n","    samples_likelihood = pk[\"samples_likelihood\"]\n","    all_like_mean[s]=samples_likelihood.mean()\n","    \n","    plt.plot(range(N_iterations_MCMC), samples_likelihood, label=\"sub-pop\" + str(s+1))\n","    plt.legend(loc='upper right')\n","    plt.xlabel('MCMC samples')\n","    plt.ylabel('Log likelihood')\n","    plt.title('MCMC trace')\n","plt.xlim(0,N_iterations_MCMC+0.15*N_iterations_MCMC)\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["s = 1#np.argmax(all_like_mean)\n","M = len(zdata) \n","\n","pickle_filename_s = output_folder + f'/pickle_files/sustain_sol_subtype' + str(s) + '.pickle'\n","pk = pd.read_pickle(pickle_filename_s)\n","\n","for variable in ['ml_subtype', 'prob_ml_subtype', 'ml_stage', 'prob_ml_stage',]:\n","    zdata.loc[:,variable] = pk[variable]\n","for i in range(s):\n","    zdata.loc[:,'prob_S%s'%i] = pk['prob_subtype'][:,i]\n","\n","zdata.to_csv(f'{output_folder}/sustain_sol')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["samples_sequence = pk[\"samples_sequence\"]\n","samples_f = pk[\"samples_f\"]\n","\n","# use this information to plot the positional variance diagrams\n","if s==0:\n","    tmp=pySuStaIn.ZscoreSustain._plot_sustain_model(sustain_input, samples_sequence, samples_f, M, figsize=(25,5))\n","else:\n","    tmp=pySuStaIn.ZscoreSustain._plot_sustain_model(sustain_input, samples_sequence, samples_f, M, subtype_order=(0,1), figsize=(25,5))\n","\n","plt.tight_layout()\n","plt.savefig(f'{output_folder}/sustain_sol',dpi=dpi)"]},{"cell_type":"markdown","metadata":{},"source":["# Analysis"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["sol_aux = data.copy()\n","sol_aux['sustain_subpop']=[1 if _>0.5 else 0 for _ in zdata['prob_S0']]\n","\n","sub_pop_counts = sol_aux.groupby('subj_id')['sustain_subpop'].value_counts().unstack(fill_value=0).reset_index()\n","sub_pop_counts['ratio']=sub_pop_counts[0]/sub_pop_counts[1]\n","sub_pop_counts['variance']=sub_pop_counts['ratio']*(sub_pop_counts['ratio']-1)\n","sub_pop_counts['sustain_subpop_mean']=[0 if _>1 else 1 for _ in sub_pop_counts['ratio']]\n","sub_pop_counts['dpmost_subpop']=[1 if _>0.5 else 0 for _ in dpmost.pi]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fpr, tpr, _=roc_curve(sub_pop_counts['sustain_subpop_mean'].values, 1-dpmost.pi)\n","fpr_2, tpr_2, _=roc_curve(sub_pop_counts['sustain_subpop_mean'].values, dpmost.pi)\n","\n","if auc(fpr, tpr)>auc(fpr_2, tpr_2):\n","    tpr=tpr_2\n","    fpr=fpr_2"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fig, ax=plt.subplots(1,3, figsize=(15,3))\n","plt.sca(ax[0])\n","plt.plot(tpr,fpr)\n","plt.plot([0, 1], [0, 1], linestyle='--', linewidth=1, color='r', label='Random guess')\n","plt.xticks([0, 0.25, 0.5, 0.75, 1])\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.title(r'ROC curve')\n","\n","plt.sca(ax[1])\n","plt.plot(sub_pop_counts['sustain_subpop_mean'].values, 'r.', alpha=0.5, label='sustain')\n","plt.plot(sub_pop_counts['dpmost_subpop'].values, 'bx', alpha=0.5, label='dpmost')\n","plt.title('Sub-populations differences')\n","plt.legend()\n","\n","plt.sca(ax[2])\n","plt.plot(sub_pop_counts['variance'].values, '.')\n","plt.title('Variance')\n","\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# Biomarkers Progression"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["names=['data.png', 'gppm_sol.png', 'dpmost_sol.png', 'sustain_sol.png']\n","titles=['data', 'gppm', 'dp-most', 'sustain']\n","\n","fig, ax=plt.subplots(len(names),1, figsize=(5*n_features,5*len(names)))\n","for idx in range(len(names)):\n","    plt.sca(ax[idx])\n","    img = mpimg.imread(f'{output_folder}/' + names[idx])\n","    plt.imshow(img)\n","    plt.title(titles[idx], fontsize=20)\n","    plt.axis('off')\n","    plt.tight_layout()\n","    \n","plt.savefig(f'{output_folder}/sol_comparison',dpi=dpi)\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# Distributions"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["aux=zdata.copy()\n","aux['algorithm']=['sustain' for _ in range(aux.shape[0])]\n","\n","a=np.zeros(aux.shape[0])\n","for idx in range(aux.shape[0]):\n","    indices = torch.nonzero(torch.tensor(data['subj_id'].unique()) == aux['subj_id'].values[idx], as_tuple=True)[0].item()\n","    a[idx]= 0 if sub_pop_counts['ratio'][indices] > 0.5 else 1\n","aux['est_subpop']=a\n","\n","\n","aux = aux.drop(columns=['ml_subtype', 'prob_ml_subtype', 'ml_stage', 'prob_ml_stage', 'prob_S0'])\n","\n","aux_2=dpmost.data.copy()\n","aux_2['algorithm']=['dpmost' for _ in range(aux_2.shape[0])]\n","aux_2['est_subpop']=dpmost.est_subpop\n","\n","aux_3=pd.concat([aux, aux_2])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fig, ax=plt.subplots(1,len(data.columns[2:]),figsize=(5*len(data.columns[2:]),5), sharex=True, sharey=True)\n","for i in range(len(data.columns[2:])):\n","    plt.sca(ax[i])\n","    legend=True if i==0 else False\n","    sns.violinplot(data=aux_3, y=data.columns[2:][i], x='algorithm', hue='est_subpop', saturation=0.7, orient='v', \n","                   split=True, gap=.05, bw_adjust=1.9 , inner='quartile', legend=legend, linewidth=1, palette=['steelblue','lightcoral'])\n","    if i==0: \n","        handles, _ = ax[0].get_legend_handles_labels()\n","        plt.legend(handles, ['Sub-population 1', 'Sub-population 2'], loc=\"upper left\")\n","\n","    plt.title(data.columns[2:][i])\n","    plt.xlabel('', fontsize=0)\n","    plt.ylabel('', fontsize=0)\n","plt.tight_layout()\n","plt.savefig(f'{output_folder}/sol_distributions', dpi=dpi)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":2}
